{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61669d16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-14T04:34:53.331927Z",
     "start_time": "2023-01-14T04:34:53.315804Z"
    }
   },
   "source": [
    "**_워드 임베딩?_**    \n",
    "-> 텍스트를 컴퓨터가 이해할 수 있도록 수치화하는 하나의 방법   \n",
    "-> 각 단어를 인공 신경망 학습을 통해 벡터화함\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3ff5a9",
   "metadata": {},
   "source": [
    "# 1. 워드 임베딩\n",
    "- 단어를 벡터로 표현하는 방법.\n",
    "- 단어를 밀집 표현으로 변환\n",
    "\n",
    "## 1.1 희소 표현(Sparse Representation) \n",
    "벡터 또는 행렬의 값이 대부분 0으로 표현되는 방법.   \n",
    "ex) 원-핫 인코딩을 통해 나온 원-핫 벡터는 표현하고자 하는 단어의 인덱스만 1이고 나머지 인덱스는 전부 0으로 표현   \n",
    "ex) DTM : 특정 문서에 다수 등장한 단어가 다른 많은 문서에서는 등장하지 않으면 행렬의 많은 값이 0이 된다.   \n",
    "- 문제점   \n",
    "    1) 단어 개수가 늘어나면 벡터의 차원이 한없이 커진다. -> 공간낭비   \n",
    "    2) 단어의 의미를 표현하지 못한다.   \n",
    "    3) 단어 벡터 간 유의미한 유사도를 계산할 수 없다. \n",
    "    \n",
    "## 1.2 밀집 표현(Dense Representation)\n",
    "사용자가 설정한 값으로 모든 단어의 벡터 표현의 차원을 맞추며, 벡터값은 0과 1만이 아니라 실수값을 갖는다.\n",
    "\n",
    "## 1.3 워드 임베딩(Word Embedding)\n",
    "단어를 밀집 벡터(dense vector)의 형태로 표현하는 방법.   \n",
    "이 밀집 벡터를 워드 임베딩 과정을 통해 나온 결과라고 하여 임베딩 벡터라고도 한다.\n",
    "<img src=\"./09-1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94334d94",
   "metadata": {},
   "source": [
    "# 2. 워드투벡터(word2Vec)\n",
    "단어 벡터 간 유의미한 유사도를 파악할 수 있도록 단어의 의미를 수치화하는 대표적인 방법\n",
    "\n",
    "### 분산 표현\n",
    "희소 표현 방법의 대안으로, 단어의 의미를 다차원 공간에 벡터화하는 표현 방법.   \n",
    "분포 가설을 이용하여 **텍스트를 학습**하고, 단어의 의미를 벡터의 여러 차원에 분산하여 표현.\n",
    "- 분포 가설 : 비슷한 문맥에서 등장하는 단어들은 비슷한 의미를 가진다.   \n",
    "\n",
    "분산 표현을 이용하여 단어 간 의미적 유사성을 벡터화하는 작업을 **워드 임베딩**이라 부르며, 이렇게 표현된 벡터를 **임베딩 벡터**라 한다.   \n",
    "\n",
    "#### Word2Vec의 학습 방식에는 CBOW(Continuous Bag of Words)와 Skip-Gram 두 가지 방식이 있다.\n",
    "\n",
    "## 1) CBOW(Continuous Bag of Words)\n",
    "주변에 있는 단어들을 입력으로 중간에 있는 단어들을 예측하는 방법    \n",
    "- 윈도우 : 중심 단어를 예측하기 위해서 앞, 뒤로 몇 개의 단어를 볼지에 대한 범위   \n",
    "- 윈도우 크기가 n이라면, 실제 중심 단어를 예측하기 위해 참고하려고 하는 주변 단어의 개수는 2n개이다.   \n",
    "\n",
    "투사층에서 입력 벡터인 2n개의 벡터의 평균을 구한다.\n",
    "  \n",
    "## 2) Skip-gram\n",
    "중간에 있는 단어들을 입력으로 주변 단어들을 예측하는 방법   \n",
    "중심 단어에 대해서 주변 단어를 예측하므로 투사층에서 벡터들의 평균을 구하는 과정이 없다.\n",
    "\n",
    "**_1), 2)에 대한 추가설명은 꼭 교재 참고!!(그림이 많고 책에 나온 내용을 이해하는 게 중요해서 따로 요약X)_**\n",
    "- CBOW, Skip-gram 설명 : https://wikidocs.net/22660\n",
    "    \n",
    "## NNLM  VS Word2Vec\n",
    "\n",
    "<img src=\"./09-2.png\">\n",
    "\n",
    "### NNLM\n",
    "- 단어 벡터 간 유사도를 구할 수 있도록 워드 임베딩 개념 도입\n",
    "- 다음 단어를 예측하는 언어 모델 구현이 목적 -> 다음 단어를 예측\n",
    "- 예측 단어의 이전 단어들만을 참고\n",
    "- 활성화 함수가 있는 은닉층 존재\n",
    "\n",
    "### Word2VEC\n",
    "- 워드 임베딩 자체에 집중. NNLM의 느린 학습 속도와 정확도 개선\n",
    "- 워드 임베딩 자체가 목적. -> 중심 단어를 예측\n",
    "- 예측 단어의 전, 후 단어들을 모두 참고\n",
    "- 활성화 함수가 있는 은닉층 제거 -> 학습 속도에 강점."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510c4a08",
   "metadata": {},
   "source": [
    "# 3. 영어/한국어 Word2Vec 실습\n",
    "gensim 패키지에서 제공하는 이미 구현된 Word2Vec을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90882a9",
   "metadata": {},
   "source": [
    "## 3.1 영어 Word2Vec 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c13bba",
   "metadata": {},
   "source": [
    "### 3.1.2 훈련 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7cb9aaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:01:29.781197Z",
     "start_time": "2023-01-15T02:01:27.796637Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from lxml import etree\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77ab461e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:01:36.558681Z",
     "start_time": "2023-01-15T02:01:29.784199Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ted_en-20160408.xml', <http.client.HTTPMessage at 0x23330969970>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 데이터 다운로드 - xml문서형식\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/ukairia777/tensorflow-nlp-tutorial\\\n",
    "/main/09.%20Word%20Embedding/dataset/ted_en-20160408.xml\", filename=\"ted_en-20160408.xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a955574",
   "metadata": {},
   "source": [
    "> 현재 경로로 데이터가 다운로드된다.   \n",
    "\\<content>, \\</content> 사이의 내용들은 전처리하고, Laughter나 Applause와 같은 배경음을 나타내는 단어도 제거해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6d5b14f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:01:39.586102Z",
     "start_time": "2023-01-15T02:01:36.561681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lxml.etree._ElementTree at 0x2332f56cb80>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련 데이터 전처리 코드\n",
    "targetXML = open('ted_en-20160408.xml', 'r', encoding='UTF8')\n",
    "target_text = etree.parse(targetXML)\n",
    "target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90ea7f8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:01:39.741570Z",
     "start_time": "2023-01-15T02:01:39.588992Z"
    }
   },
   "outputs": [],
   "source": [
    "# xml 파일로부터 <content>와 </content> 사이의 내용만 가져온다.\n",
    "parse_text = '\\n'.join(target_text.xpath('//content/text()'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b795bccb",
   "metadata": {},
   "source": [
    "> **xpath문법 참고**\n",
    "> - https://velog.io/@mjhuh263/TIL-23-HTML-XPATH-%EB%AC%B8%EB%B2%95%EA%B3%BC-selenium%EC%97%90-XPATH-%EC%9D%B4%EC%9A%A9%ED%95%98%EA%B8%B0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b2550ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:01:39.803534Z",
     "start_time": "2023-01-15T02:01:39.744615Z"
    }
   },
   "outputs": [],
   "source": [
    "# 정규 표현식의 sub 모듈을 통해 content 중간에 등장하는 (Audio), (Laughter) 등의 배경음 부분을 제거.\n",
    "# 해당 코드는 괄호로 구성된 내용을 제거.\n",
    "content_text = re.sub(r'\\([^)]*\\)', '', parse_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6624e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-14T06:56:51.702408Z",
     "start_time": "2023-01-14T06:56:51.646536Z"
    }
   },
   "source": [
    "> **re.sub 참고**\n",
    "> - https://clolee.tistory.com/17\n",
    "\n",
    "> **정규표현식 참고**\n",
    "> - https://wikidocs.net/4308\n",
    "> - https://uipath.tistory.com/91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06157cfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:02:09.129280Z",
     "start_time": "2023-01-15T02:01:39.806529Z"
    }
   },
   "outputs": [],
   "source": [
    "# 입력 코퍼스에 대해서 NLTK를 이용하여 문장 토큰화를 수행.\n",
    "sent_text = sent_tokenize(content_text)\n",
    "\n",
    "# 각 문장에 대해서 구두점을 제거하고, 대문자를 소문자로 변환.\n",
    "normalized_text = []\n",
    "for string in sent_text:\n",
    "    tokens = re.sub(r\"[^a-z0-9]+\", \" \", string.lower())\n",
    "    normalized_text.append(tokens)\n",
    "\n",
    "# 각 문장에 대해서 NLTK를 이용하여 단어 토큰화를 수행.\n",
    "result = [word_tokenize(sentence) for sentence in normalized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61e8fb4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:02:09.145196Z",
     "start_time": "2023-01-15T02:02:09.131241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 개수 : 273424\n"
     ]
    }
   ],
   "source": [
    "print('총 샘플의 개수 : {}'.format(len(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "525b26f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:02:09.160627Z",
     "start_time": "2023-01-15T02:02:09.147868Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['here', 'are', 'two', 'reasons', 'companies', 'fail', 'they', 'only', 'do', 'more', 'of', 'the', 'same', 'or', 'they', 'only', 'do', 'what', 's', 'new']\n",
      "['to', 'me', 'the', 'real', 'real', 'solution', 'to', 'quality', 'growth', 'is', 'figuring', 'out', 'the', 'balance', 'between', 'two', 'activities', 'exploration', 'and', 'exploitation']\n",
      "['both', 'are', 'necessary', 'but', 'it', 'can', 'be', 'too', 'much', 'of', 'a', 'good', 'thing']\n"
     ]
    }
   ],
   "source": [
    "# 샘플 3개만 출력 - 토큰화 수행되었음을 확인 가능\n",
    "for line in result[:3]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b578dd94",
   "metadata": {},
   "source": [
    "### 3.1.2 Word2Vec 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e0a82d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:02:09.176651Z",
     "start_time": "2023-01-15T02:02:09.165618Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeaee272",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:02:20.715586Z",
     "start_time": "2023-01-15T02:02:09.183674Z"
    }
   },
   "outputs": [],
   "source": [
    "# Word2Vec 훈련시키기\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = Word2Vec(sentences=result, vector_size=100, window=5, min_count=5, workers=4, sg=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7f7d4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-14T07:06:28.242575Z",
     "start_time": "2023-01-14T07:06:28.229361Z"
    }
   },
   "source": [
    "> Word2Vec의 하이퍼파라미터\n",
    "> - vector_size = 워드 벡터의 특징 값. 즉, 임베딩 된 벡터의 차원.\n",
    "> - window = 컨텍스트 윈도우 크기\n",
    "> - min_count = 단어 최소 빈도 수 제한 (빈도가 적은 단어들은 학습X)\n",
    "> - workers = 학습을 위한 프로세스 수\n",
    "> - sg = 0은 CBOW, 1은 Skip-gram.\n",
    "\n",
    "> **오류해결** : __init__() got an unexpected keyword argument 'size'\n",
    "> - https://taepseon.tistory.com/165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd0700ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:02:20.762595Z",
     "start_time": "2023-01-15T02:02:20.716568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.8594766855239868), ('guy', 0.7988778948783875), ('lady', 0.7585463523864746), ('girl', 0.7442930340766907), ('boy', 0.7347717881202698), ('gentleman', 0.706429660320282), ('poet', 0.7047451734542847), ('kid', 0.687045693397522), ('soldier', 0.687027096748352), ('surgeon', 0.6518595218658447)]\n"
     ]
    }
   ],
   "source": [
    "# model.wv.most_similar : 입력한 단어에 대해서 가장 유사한 단어들을 출력\n",
    "model_result = model.wv.most_similar(\"man\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "677a02d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:02:23.409804Z",
     "start_time": "2023-01-15T02:02:20.765597Z"
    }
   },
   "outputs": [],
   "source": [
    "# Word2Vec 모델 저장하고 로드하기\n",
    "model.wv.save_word2vec_format('eng_w2v') # 모델 저장\n",
    "loaded_model = KeyedVectors.load_word2vec_format(\"eng_w2v\") # 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdd71239",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:02:23.440463Z",
     "start_time": "2023-01-15T02:02:23.413450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.8594766855239868), ('guy', 0.7988778948783875), ('lady', 0.7585463523864746), ('girl', 0.7442930340766907), ('boy', 0.7347717881202698), ('gentleman', 0.706429660320282), ('poet', 0.7047451734542847), ('kid', 0.687045693397522), ('soldier', 0.687027096748352), ('surgeon', 0.6518595218658447)]\n"
     ]
    }
   ],
   "source": [
    "model_result = loaded_model.most_similar(\"man\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef0100",
   "metadata": {},
   "source": [
    "## 3.2 한국어 Word2Vec 만들기(네이버 영화 리뷰)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64802b7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:02:24.906008Z",
     "start_time": "2023-01-15T02:02:23.444421Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78ecd345",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:02:27.372999Z",
     "start_time": "2023-01-15T02:02:24.909339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ratings.txt', <http.client.HTTPMessage at 0x23370804a00>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 네이버 영화 리뷰 데이터 다운로드\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master\\\n",
    "/ratings.txt\", filename=\"ratings.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffb63598",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:02:27.856873Z",
     "start_time": "2023-01-15T02:02:27.375473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_table('ratings.txt')\n",
    "train_data[:5] # 상위 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da287f65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:02:27.872511Z",
     "start_time": "2023-01-15T02:02:27.859870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data)) # 리뷰 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aabb2f3b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:02:27.934676Z",
     "start_time": "2023-01-15T02:02:27.875568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# NULL 값 존재 유무\n",
    "print(train_data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ad6d474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:02:28.014043Z",
     "start_time": "2023-01-15T02:02:27.936659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "199992\n"
     ]
    }
   ],
   "source": [
    "# 결측값 제거\n",
    "train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인\n",
    "print(len(train_data)) # 리뷰 개수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "908eb8ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:02:28.341392Z",
     "start_time": "2023-01-15T02:02:28.015549Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hkny0\\AppData\\Local\\Temp\\ipykernel_10512\\3523926270.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업...      1\n",
       "2   4655635                   폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고      1\n",
       "3   9251303   와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지      1\n",
       "4  10067386                         안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화      1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정규 표현식을 통한 한글 외 문자 제거\n",
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_data[:5] # 상위 5개 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f259cb",
   "metadata": {},
   "source": [
    "> str.replace의 argument에 관한 future warning   \n",
    "> - The default value of regex will change from True to False in a future version.\n",
    "> - https://stackoverflow.com/questions/66603854/futurewarning-the-default-value-of-regex-will-change-from-true-to-false-in-a-fu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a95ebb85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:13:15.895067Z",
     "start_time": "2023-01-15T02:02:28.345296Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 199992/199992 [10:45<00:00, 309.68it/s]\n"
     ]
    }
   ],
   "source": [
    "## 불용어 제거\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 불용어 정의\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "# 형태소 분석기 OKT를 사용한 토큰화 작업 (다소 시간 소요)\n",
    "okt = Okt()\n",
    "\n",
    "tokenized_data = []\n",
    "for sentence in tqdm(train_data['document']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
    "    tokenized_data.append(stopwords_removed_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffd87a1",
   "metadata": {},
   "source": [
    "> **<tqdm 사용법>**\n",
    "> - 반복문에서 진행률을 progress bar로 표혀해주고 남은 시간 정보까지 알려주는 모듈\n",
    "> - https://zephyrus1111.tistory.com/305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f14c53e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:13:16.723237Z",
     "start_time": "2023-01-15T02:13:15.899067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 72\n",
      "리뷰의 평균 길이 : 10.716703668146726\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 리뷰 길이 분포 확인\n",
    "print('리뷰의 최대 길이 :',max(len(review) for review in tokenized_data))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, tokenized_data))/len(tokenized_data))\n",
    "plt.hist([len(review) for review in tokenized_data], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6673b370",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:13:22.717142Z",
     "start_time": "2023-01-15T02:13:16.726234Z"
    }
   },
   "outputs": [],
   "source": [
    "# Word2Vec으로 토큰화 된 네이버 영화 리뷰 데이터를 학습\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model2 = Word2Vec(sentences = tokenized_data, vector_size = 100, window = 5, min_count = 5, workers = 4, sg = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af6c58a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:13:22.732355Z",
     "start_time": "2023-01-15T02:13:22.720345Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16477, 100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 완성된 임베딩 매트릭스의 크기 확인\n",
    "model2.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "434ba968",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:47:28.671713Z",
     "start_time": "2023-01-15T03:47:28.652701Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('안성기', 0.8951629996299744), ('한석규', 0.878433108329773), ('김수현', 0.8374939560890198), ('엄태웅', 0.8361460566520691), ('김명민', 0.8339917063713074), ('메릴', 0.83388751745224), ('최민수', 0.8326302766799927), ('송강호', 0.8280673027038574), ('박중훈', 0.8279872536659241), ('윤제문', 0.8226507902145386)]\n"
     ]
    }
   ],
   "source": [
    "# '최민식'과 유사한 단어 출력\n",
    "print(model2.wv.most_similar(\"최민식\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb504577",
   "metadata": {},
   "source": [
    "## 3.3 사전 훈련된 Word2Vec 임베딩(Pre-trained Word2Vec embedding) 소개\n",
    "갖고 있는 훈련 데이터의 양이 부족한 상황이라면, 위키피디아 등의 방대한 데이터로 사전에 훈련된 워드 임베딩(pre-trained word embedding vector)을 가지고 와서 해당 벡터들의 값을 원하는 작업에 사용 할 수도 있다.\n",
    "\n",
    "구글이 제공하는 사전 훈련된 Word2Vec 모델을 사용하는 방법에 대해 알아보자.   \n",
    "- 모델 다운로드 경로 : https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93790815",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:13:23.409147Z",
     "start_time": "2023-01-15T02:13:23.409147Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import urllib.request\n",
    "\n",
    "# 구글의 사전 훈련된 Word2Vec 모델을 로드.\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd41031",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:13:23.410153Z",
     "start_time": "2023-01-15T02:13:23.410153Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델의 크기 확인\n",
    "print(word2vec_model.vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e257d00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:13:23.411221Z",
     "start_time": "2023-01-15T02:13:23.411221Z"
    }
   },
   "outputs": [],
   "source": [
    "# 두 단어의 유사도 계산 연습\n",
    "print(word2vec_model.similarity('this', 'is'))\n",
    "print(word2vec_model.similarity('post', 'book'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c2f87e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T02:13:23.412225Z",
     "start_time": "2023-01-15T02:13:23.412225Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 단어 'book'의 벡터 출력\n",
    "print(word2vec_model['book'][:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c6bf21",
   "metadata": {},
   "source": [
    "# 4. 네거티브 샘플링을 이용한 Word2Vec 구현(Skip-Gram with Negative Sampling, SGNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc83ca",
   "metadata": {},
   "source": [
    "## 4.1 네거티브 샘플링(Negative Sampling)\n",
    "보통의 Word2Vec는 단어 집합의 크기가 수만 이상에 달한다면 학습하기 꽤나 무거운 모델이 된다. **네거티브 샘플링**은 Word2Vec이 학습 과정에서 전체 단어 집합이 아니라 일부 단어 집합에만 집중할 수 있도록 하는 방법. 기존의 단어 집합을 이진 분류 문제를 위한 데이터셋으로 변환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad10b71",
   "metadata": {},
   "source": [
    "## 4.2 네거티브 샘플링 Skip-Gram(Skip-Gram with Negative Sampling, SGNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da5a4e6",
   "metadata": {},
   "source": [
    "앞서 배운 Skip-gram은 중심 단어를 입력에 사용하여, 주변 단어를 예측하는 모델이다.   \n",
    "반면 네거티브 샘플링을 사용하는 Skip-gram(이하 SGNS)는 중심 단어와 주변 단어가 모두 입력이 되고, 이 두 단어가 실제로 윈도우 크기 내에 존재하는 이웃 관계인지에 대한 확률을 예측하는 모델이다.\n",
    "\n",
    "**_추가설명은 꼭 교재 참고!!_**\n",
    "- https://wikidocs.net/69141"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3071fa03",
   "metadata": {},
   "source": [
    "## 4.3 20뉴스그룹 데이터 전처리하기\n",
    "중심 단어, 주변 단어의 관계가 성립하기 위해 데이터는 하나의 샘플에 최소 단어 2개가 있어야 한다. 따라서 전처리 과정에서 지속적으로 이를 만족하지 않는 샘플들을 제거한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1400b272",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:47:43.988906Z",
     "start_time": "2023-01-15T03:47:37.403256Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import fetch_20newsgroups    # 20뉴스그룹 데이터 사용\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06602ce6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:47:45.316259Z",
     "start_time": "2023-01-15T03:47:43.991054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플 수 : 11314\n"
     ]
    }
   ],
   "source": [
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))\n",
    "documents = dataset.data\n",
    "print('총 샘플 수 :',len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25078c69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:47:45.331725Z",
     "start_time": "2023-01-15T03:47:45.321190Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Well i'm not sure about the story nad it did seem biased. What\\nI disagree with is your statement that the U.S. Media is out to\\nruin Israels reputation. That is rediculous. The U.S. media is\\nthe most pro-israeli media in the world. Having lived in Europe\\nI realize that incidences such as the one described in the\\nletter have occured. The U.S. media as a whole seem to try to\\nignore them. The U.S. is subsidizing Israels existance and the\\nEuropeans are not (at least not to the same degree). So I think\\nthat might be a reason they report more clearly on the\\natrocities.\\n\\tWhat is a shame is that in Austria, daily reports of\\nthe inhuman acts commited by Israeli soldiers and the blessing\\nreceived from the Government makes some of the Holocaust guilt\\ngo away. After all, look how the Jews are treating other races\\nwhen they got power. It is unfortunate.\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b101ad5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:47:46.921748Z",
     "start_time": "2023-01-15T03:47:45.339715Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hkny0\\AppData\\Local\\Temp\\ipykernel_10512\\2716589182.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n"
     ]
    }
   ],
   "source": [
    "### 전처리 진행\n",
    "# list -> dataframe\n",
    "news_df = pd.DataFrame({'document':documents})  #document라는 열이름 사용\n",
    "# 특수 문자 제거\n",
    "news_df['clean_doc'] = news_df['document'].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "# 길이가 3이하인 단어는 제거 (길이가 짧은 단어 제거)\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "# 전체 단어에 대한 소문자 변환\n",
    "news_df['clean_doc'] = news_df['clean_doc'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a82317d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:47:46.952293Z",
     "start_time": "2023-01-15T03:47:46.923947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측값 유무 확인\n",
    "news_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5261802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:47:46.984127Z",
     "start_time": "2023-01-15T03:47:46.956307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty값 유무 확인 (empty값->null값변환->결측값유무 다시확인)\n",
    "news_df.replace(\"\", float(\"NaN\"), inplace=True)\n",
    "news_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "219dcd45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:47:47.014907Z",
     "start_time": "2023-01-15T03:47:46.987126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플 수 : 10995\n"
     ]
    }
   ],
   "source": [
    "# 결측값 제거\n",
    "news_df.dropna(inplace=True)\n",
    "print('총 샘플 수 :',len(news_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e768d1cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:47:53.488650Z",
     "start_time": "2023-01-15T03:47:47.017903Z"
    }
   },
   "outputs": [],
   "source": [
    "# 불용어 제거\n",
    "stop_words = stopwords.words('english')\n",
    "tokenized_doc = news_df['clean_doc'].apply(lambda x: x.split())\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "tokenized_doc = tokenized_doc.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40af07d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:47:53.519909Z",
     "start_time": "2023-01-15T03:47:53.490655Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플 수 : 10940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\data\\lib\\site-packages\\numpy\\lib\\function_base.py:5030: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asarray(arr)\n"
     ]
    }
   ],
   "source": [
    "# 단어가 1개 이하인 샘플의 인덱스를 찾아서 저장하고, 해당 샘플들은 제거.\n",
    "drop_train = [index for index, sentence in enumerate(tokenized_doc) if len(sentence) <= 1]\n",
    "tokenized_doc = np.delete(tokenized_doc, drop_train, axis=0)  # 행 삭제\n",
    "print('총 샘플 수 :',len(tokenized_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf28d88",
   "metadata": {},
   "source": [
    "> **동일 배열 차원의 각 차원의 요소 길이가 다른 경우**\n",
    "> - https://homzzang.com/b/py-311\n",
    "> - https://statools.tistory.com/322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a30ad10f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:47:55.771561Z",
     "start_time": "2023-01-15T03:47:53.523862Z"
    }
   },
   "outputs": [],
   "source": [
    "# 단어 집합 생성 후 정수 인코딩\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tokenized_doc)\n",
    "\n",
    "word2idx = tokenizer.word_index\n",
    "idx2word = {value : key for key, value in word2idx.items()}  # dict comprehension\n",
    "encoded = tokenizer.texts_to_sequences(tokenized_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e63efd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:47:55.787742Z",
     "start_time": "2023-01-15T03:47:55.773562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9, 59, 603, 207, 3278, 1495, 474, 702, 9470, 13686, 5533, 15227, 702, 442, 702, 70, 1148, 1095, 1036, 20294, 984, 705, 4294, 702, 217, 207, 1979, 15228, 13686, 4865, 4520, 87, 1530, 6, 52, 149, 581, 661, 4406, 4988, 4866, 1920, 755, 10668, 1102, 7837, 442, 957, 10669, 634, 51, 228, 2669, 4989, 178, 66, 222, 4521, 6066, 68, 4295], [1026, 532, 2, 60, 98, 582, 107, 800, 23, 79, 4522, 333, 7838, 864, 421, 3825, 458, 6488, 458, 2700, 4730, 333, 23, 9, 4731, 7262, 186, 310, 146, 170, 642, 1260, 107, 33568, 13, 985, 33569, 33570, 9471, 11491]]\n"
     ]
    }
   ],
   "source": [
    "print(encoded[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e91106ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:47:55.803343Z",
     "start_time": "2023-01-15T03:47:55.791818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 64277\n"
     ]
    }
   ],
   "source": [
    "# 단어 집합 크기 확인\n",
    "vocab_size = len(word2idx) + 1 \n",
    "print('단어 집합의 크기 :', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9438a3b",
   "metadata": {},
   "source": [
    "## 4.4 네거티브 샘플링을 통한 데이터셋 구성하기\n",
    "skipgrams 사용 : 네거티브 샘플링을 위해 케라스에서 제공하는 전처리 도구   \n",
    "상위 10개의 뉴스그룹 샘플에 대해서만 수행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4fa786a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:47:55.866599Z",
     "start_time": "2023-01-15T03:47:55.806389Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import skipgrams\n",
    "# 네거티브 샘플링 - 상위 10개 샘플만\n",
    "skip_grams = [skipgrams(sample, vocabulary_size=vocab_size, window_size=10) for sample in encoded[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1f447320",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:47:55.880649Z",
     "start_time": "2023-01-15T03:47:55.869637Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(israels (13686), media (702)) -> 1\n",
      "(commited (7837), clearly (661)) -> 1\n",
      "(lived (1148), seem (207)) -> 1\n",
      "(shame (4988), received (634)) -> 1\n",
      "(letter (705), tyndale (36628)) -> 0\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 샘플인 skip_grams[0] 내 skipgrams로 형성된 데이터셋 확인\n",
    "pairs, labels = skip_grams[0][0], skip_grams[0][1]\n",
    "for i in range(5):\n",
    "    print(\"({:s} ({:d}), {:s} ({:d})) -> {:d}\".format(\n",
    "          idx2word[pairs[i][0]], pairs[i][0], \n",
    "          idx2word[pairs[i][1]], pairs[i][1], \n",
    "          labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "acf38bd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:47:55.896742Z",
     "start_time": "2023-01-15T03:47:55.884181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 10\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플 수 :',len(skip_grams))  # 상위10게"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1c4e1584",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:47:55.912053Z",
     "start_time": "2023-01-15T03:47:55.899848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2220\n",
      "2220\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 뉴스그룹 샘플에 대해서 생긴 pairs와 labels의 개수\n",
    "print(len(pairs))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c310d345",
   "metadata": {},
   "source": [
    "> 10개의 뉴스그룹 샘플 각각은 수많은 중심 단어, 주변 단어의 쌍으로 된 샘플들을 갖고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980a336e",
   "metadata": {},
   "source": [
    "## 4.5 Skip-Gram with Negative Sampling(SGNS) 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b585e453",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:47:55.928152Z",
     "start_time": "2023-01-15T03:47:55.915982Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Reshape, Activation, Input\n",
    "from tensorflow.keras.layers import Dot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "edcaff30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:47:56.695763Z",
     "start_time": "2023-01-15T03:47:55.931128Z"
    }
   },
   "outputs": [],
   "source": [
    "# 임베딩 벡터의 차원 : 100\n",
    "embedding_dim = 100\n",
    "\n",
    "## 임베딩 층 두 개 추가\n",
    "\n",
    "# 1) 중심 단어를 위한 임베딩 테이블\n",
    "w_inputs = Input(shape=(1, ), dtype='int32')\n",
    "word_embedding = Embedding(vocab_size, embedding_dim)(w_inputs)\n",
    "\n",
    "# 2) 주변 단어를 위한 임베딩 테이블\n",
    "c_inputs = Input(shape=(1, ), dtype='int32')\n",
    "context_embedding  = Embedding(vocab_size, embedding_dim)(c_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d3f626",
   "metadata": {},
   "source": [
    "각 단어는 임베딩 테이블을 거쳐서 내적을 수행하고, 내적의 결과는 1 또는 0을 예측하기 위해서 시그모이드 함수를 활성화 함수로 거쳐 최종 예측값을 얻는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33addd30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:47:57.305809Z",
     "start_time": "2023-01-15T03:47:56.701151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 100)       6427700     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 1, 100)       6427700     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 1, 1)         0           ['embedding[0][0]',              \n",
      "                                                                  'embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1)            0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 1)            0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,855,400\n",
      "Trainable params: 12,855,400\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "dot_product = Dot(axes=2)([word_embedding, context_embedding])\n",
    "dot_product = Reshape((1,), input_shape=(1, 1))(dot_product)\n",
    "output = Activation('sigmoid')(dot_product)\n",
    "\n",
    "# 모델 생성\n",
    "model = Model(inputs=[w_inputs, c_inputs], outputs=output)\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "plot_model(model, to_file='model3.png', show_shapes=True, show_layer_names=True, rankdir='TB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "905d61ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:48:09.981671Z",
     "start_time": "2023-01-15T03:47:57.309799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 Loss : 6.931175768375397\n",
      "Epoch : 2 Loss : 6.906608879566193\n",
      "Epoch : 3 Loss : 6.881051659584045\n",
      "Epoch : 4 Loss : 6.850699603557587\n",
      "Epoch : 5 Loss : 6.813078224658966\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 : 5 epoch\n",
    "for epoch in range(1, 6):\n",
    "    loss = 0\n",
    "    for _, elem in enumerate(skip_grams):\n",
    "        first_elem = np.array(list(zip(*elem[0]))[0], dtype='int32')\n",
    "        second_elem = np.array(list(zip(*elem[0]))[1], dtype='int32')\n",
    "        labels = np.array(elem[1], dtype='int32')\n",
    "        X = [first_elem, second_elem]\n",
    "        Y = labels\n",
    "        loss += model.train_on_batch(X,Y)  \n",
    "    print('Epoch :',epoch, 'Loss :',loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b5660a",
   "metadata": {},
   "source": [
    "## 4.6 결과 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8f44c897",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:48:10.028301Z",
     "start_time": "2023-01-15T03:48:09.984671Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embed_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 학습된 임베딩 벡터들을 저장\u001b[39;00m\n\u001b[0;32m      4\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvectors.txt\u001b[39m\u001b[38;5;124m'\u001b[39m ,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(vocab_size\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[43membed_size\u001b[49m))\n\u001b[0;32m      6\u001b[0m vectors \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_weights()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word, i \u001b[38;5;129;01min\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mword_index\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embed_size' is not defined"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "\n",
    "# 학습된 임베딩 벡터들을 저장\n",
    "f = open('vectors.txt' ,'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-1, embed_size))\n",
    "vectors = model.get_weights()[0]\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    f.write('{} {}\\n'.format(word, ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()\n",
    "\n",
    "# 모델 로드\n",
    "w2v = gensim.models.KeyedVectors.load_word2vec_format('./vectors.txt', binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb0f30",
   "metadata": {},
   "source": [
    "> **Question2.**\n",
    "> - name 'embed_size' is not defined...\n",
    "> - embed_size 아니고 embedding_dim인 것 같은데 확실하지가 않다...ㅠㅠ\n",
    "\n",
    "> 질문함ㅋㅋ   \n",
    "> 마지막 6. 결과 확인하기 부분의 코드 중 \n",
    "f.write('{} {}\\n'.format(vocab_size-1, embed_size)) 라는 코드에서 \n",
    "embed_size라는 변수가 앞에서 지정되어 있지 않아서 오류가 납니다.\n",
    "이 embed_size가 혹시 앞에서 지정한 임베딩 벡터의 차원인 embedding_dim을 잘 못 쓴 것일까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3991e0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:48:10.031283Z",
     "start_time": "2023-01-15T03:48:10.031283Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v.most_similar(positive=['soldiers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8086a058",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:48:10.033316Z",
     "start_time": "2023-01-15T03:48:10.033316Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v.most_similar(positive=['doctor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c4a0ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T03:48:10.038326Z",
     "start_time": "2023-01-15T03:48:10.038326Z"
    }
   },
   "outputs": [],
   "source": [
    "w2v.most_similar(positive=['police'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99e2c85",
   "metadata": {},
   "source": [
    "# 5. 글로브(GloVe)\n",
    "* LSA : 카운트 기반\n",
    "    - 장) 코퍼스의 전체적인 통계 정보 고려\n",
    "    - 단) 단어 의미의 유추 작업에 불리\n",
    "* Word2Vec : 예측 기반\n",
    "    - 장) 단어 간 유추 작업에 유리\n",
    "    - 단) 코퍼스의 전체적인 통계 정보 반영 X\n",
    "\n",
    "\n",
    "* **글로브** : 카운트 기반(ex. LSA)과 예측 기반(ex. Word2Vec)을 모두 사용하는 방법론   \n",
    "    - Word2Vec만큼 뛰어난 성능을 보여주므로, 실제로 두 가지 모두 사용해보고 성능이 더 좋은 것을 사용하는 게 바람직하다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f097d41b",
   "metadata": {},
   "source": [
    "## 윈도우 기반 동시 등장 행렬, 동시 등장 확률, 손실 함수\n",
    "GloVe의 목표는 **임베딩 된 중심 단어와 주변 단어 벡터의 내적이 전체 코퍼스에서의 동시 등장 확률이 되도록 임베딩 벡터를 만드는 것**이다!!\n",
    "\n",
    "**추가설명은 꼭꼭꼭 교재 참고!!**\n",
    "- https://wikidocs.net/22885"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bac668e",
   "metadata": {},
   "source": [
    "## 5.2 GloVe 훈련시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f47f385e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T05:15:39.853859Z",
     "start_time": "2023-01-15T05:15:37.978029Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\programdata\\anaconda3\\envs\\data\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\programdata\\anaconda3\\envs\\data\\lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement glove-python-binary (from versions: none)\n",
      "ERROR: No matching distribution found for glove-python-binary\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\programdata\\anaconda3\\envs\\data\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\programdata\\anaconda3\\envs\\data\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (c:\\programdata\\anaconda3\\envs\\data\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install glove-python-binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c651b4a8",
   "metadata": {},
   "source": [
    "> **Question3.**   \n",
    "설치가 안돼여... 실습 못해여...ㅠㅅㅠ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe2aa878",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T05:11:34.798119Z",
     "start_time": "2023-01-15T05:11:34.734855Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'glove'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglove\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mglove\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Corpus, Glove\n\u001b[0;32m      4\u001b[0m corpus \u001b[38;5;241m=\u001b[39m Corpus() \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'glove'"
     ]
    }
   ],
   "source": [
    "from glove import Corpus, Glove\n",
    "\n",
    "corpus = Corpus() \n",
    "\n",
    "# 훈련 데이터로부터 GloVe에서 사용할 동시 등장 행렬 생성\n",
    "corpus.fit(result, window=5)\n",
    "glove = Glove(no_components=100, learning_rate=0.05)\n",
    "\n",
    "# 학습하기 : 학습에 이용할 쓰레드의 개수는 4로 설정, 에포크는 20.\n",
    "glove.fit(corpus.matrix, epochs=20, no_threads=4, verbose=True)\n",
    "glove.add_dictionary(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dffb605",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glove.most_similar(\"man\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf26a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glove.most_similar(\"boy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a617ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glove.most_similar(\"university\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b823e35",
   "metadata": {},
   "source": [
    "# 6. 패스트텍스트(FastText)\n",
    "Word2Vec를 확장한 메커니즘이지만, Word2Vec는 단어를 쪼개질 수 없는 단위로 생각한다면, FastText는 하나의 단어 안에도 여러 단어들이 존재하는 것으로 간주한다는 차이가 있다.   \n",
    "다시 말해, FastText는 내부 단어, 즉 서브워드(subword)를 고려하여 학습한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff552fa",
   "metadata": {},
   "source": [
    "## 6.1 내부 단어(subword)의 학습\n",
    "FastText에서는 각 단어를 글자 단위 n-gram의 구성으로 취급한다.   \n",
    "ex) n=3. 즉, 트라이그램(tri-gram)이고, 단어는 apple이라면   \n",
    "내부 단어 토큰은 \\<apple>에서 <ap, app, ppl, ple, le>로 5개이고, 여기에 기본적으로 <apple>을 추가해 총 6개의 토큰을 벡터화한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119f2012",
   "metadata": {},
   "source": [
    "## 6.2 모르는 단어(Out Of Vocabulary, OOV)에 대한 대응\n",
    "FastText의 인공 신경망을 학습한 후에는 데이터 셋의 모든 단어의 각 n-gram에 대해서 워드 임베딩이 된다. 이것의 장점은 **내부 단어(Subword)를 통해 모르는 단어(Out Of Vocabulary, OOV)에 대해서도 다른 단어와의 유사도를 계산할 수 있다는 점**이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f76c7c",
   "metadata": {},
   "source": [
    "## 6.3 단어 집합 내 빈도 수가 적었던 단어(Rare Word)에 대한 대응\n",
    "등장 빈도 수가 적은 단어(rare word)에 대해서는 임베딩의 정확도가 높지 않은 Word2Vec와 달리, FastText의 경우, 만약 단어가 희귀 단어라도, **그 단어의 n-gram이 다른 단어의 n-gram과 겹치는 경우**라면, Word2Vec과 비교하여 비교적 높은 임베딩 벡터값을 얻는다. 또한 같은 이유로, 노이즈(오타)가 많은 코퍼스에서 강점을 갖는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff92a321",
   "metadata": {},
   "source": [
    "## 6.4 실습으로 비교하는 Word2Vec Vs. FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bc2349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Word2Vec\n",
    "model.wv.most_similar(\"electrofishing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bbdfe9",
   "metadata": {},
   "source": [
    "> 오류남. 즉 Word2Vec는 모르는 단어에 대해서는 임베딩 벡터가 존재하지 않으므로 단어의 유사도를 계산할 수 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) FastText\n",
    "from gensim.models import FastText\n",
    "\n",
    "model = FastText(result, size=100, window=5, min_count=5, workers=4, sg=1)\n",
    "\n",
    "model.wv.most_similar(\"electrofishing\")   # 유사한 단어를 계산해서 출력함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d173123c",
   "metadata": {},
   "source": [
    "## 6.5 한국어에서의 FastText\n",
    "OOV 문제를 해결하기 위한 시도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d900e4",
   "metadata": {},
   "source": [
    "### 1) 음절 단위\n",
    "음절 단위의 임베딩의 경우에 n=3일때 ‘자연어처리’라는 단어에 대해 n-gram을 만들어보면 다음과 같다.\n",
    "* **<자연, 자연어, 연어처, 어처리, 처리>**\n",
    "\n",
    "### 2) 자모 단위(초성, 중성, 종성 단위)\n",
    "오타나 노이즈 측면에서 더 강한 임베딩을 기대해볼 수 있다.   \n",
    "‘자연어처리’라는 단어에 대해서 초성, 중성, 종성을 분리하고, 만약, 종성이 존재하지 않는다면 ‘\\_’라는 토큰을 사용한다고 가정한다면 ‘자연어처리’라는 단어는 아래와 같이 분리가 가능하며, 분리된 결과의 대한 tri-gram 적용 결과는 다음과 같다.\n",
    "* 분리된 결과 : ㅈ ㅏ _ ㅇ ㅕ ㄴ ㅇ ㅓ _ ㅊ ㅓ _ ㄹ ㅣ _\n",
    "* < ㅈ ㅏ, ㅈ ㅏ \\_, ㅏ _ ㅇ, ... 중략>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fd019f",
   "metadata": {},
   "source": [
    "# 7. 자모 단위 한국어 FastText 학습하기\n",
    "-> 웹사이트에서 비공개 처리됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024de2c1",
   "metadata": {},
   "source": [
    "# 8. 사전 훈련된 워드 임베딩(Pre-trained Word Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5019080c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
