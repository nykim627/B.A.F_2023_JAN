{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "815e2cac",
   "metadata": {},
   "source": [
    "**_DTM_** : Document Term Matrix   \n",
    "**_TF-IDF_** : Term Frequency-Inverse Document Frequency\n",
    "- 텍스트 표현 방법의 종류\n",
    "- 정보 검색과 텍스트 마이닝 분야에서 주로 사용\n",
    "\n",
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e337b869",
   "metadata": {},
   "source": [
    "# 1. 다양한 단어의 표현 방법\n",
    "## 1.1 단어의 표현 방법\n",
    "1) 국소 표현(Local Representation) 방법 / 이산(Discrete) 표현\n",
    "- 해당 단어 그 자체만 보고 특정값을 매핑하여 단어를 표현\n",
    "- 단어의 의미, 뉘앙스 표현 X\n",
    "- ex) puppy, cute, lovely 각각 숫자 맵핑\n",
    "\n",
    "2) 분산 표현(Distributed Representation) 방법 / 연속(Continuous) 표현\n",
    "- 해당 단어를 표현하고자 주변을 참고하여 단어를 표현\n",
    "- 단어의 뉘앙스 표현 O\n",
    "- ex) puppy라는 단어는 cute, lovely한 느낌이다로 단어를 정의\n",
    "\n",
    "## 1.2 단어 표현의 카테고리화\n",
    "4장 - BoW, DTM, IF-IDF    \n",
    "9장 - 워드 임베딩, Word2Vec, FastText, GloVe\n",
    "\n",
    "![그림1](./04-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5388132",
   "metadata": {},
   "source": [
    "# 2. Bag of Words(BoW)\n",
    "빈도수 기반의 단어 표현 방법. 텍스트 데이터의 수치화 표현 방법.   \n",
    "단어의 등장 순서를 고려하지 않는다.\n",
    "\n",
    "BoW를 만드는 과정\n",
    "(1) 각 단어에 고유한 정수 인덱스를 부여  # 단어 집합 생성.\n",
    "(2) 각 인덱스의 위치에 단어 토큰의 등장 횟수를 기록한 벡터 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2658e9d3",
   "metadata": {},
   "source": [
    "## 2.1 한국어 예제\n",
    "문서1) 정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.   \n",
    "문서2) 소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.   \n",
    "문서3) 정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다. 소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d411b459",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T07:18:50.959347Z",
     "start_time": "2023-01-11T07:18:50.062660Z"
    }
   },
   "outputs": [],
   "source": [
    "# 사용자 함수 생성\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "def build_bag_of_words(document):\n",
    "    # 온점 제거 및 형태소 분석\n",
    "    document = document.replace('.', '')\n",
    "    tokenized_document = okt.morphs(document)\n",
    "\n",
    "    word_to_index = {}\n",
    "    bow = []\n",
    "\n",
    "    for word in tokenized_document:  \n",
    "        if word not in word_to_index.keys():\n",
    "            word_to_index[word] = len(word_to_index)  \n",
    "            # BoW에 전부 기본값 1을 넣는다.\n",
    "            bow.insert(len(word_to_index) - 1, 1)\n",
    "        else:\n",
    "            # 재등장하는 단어의 인덱스\n",
    "            index = word_to_index.get(word)\n",
    "            # 재등장한 단어는 해당하는 인덱스의 위치에 1을 더한다.\n",
    "            bow[index] = bow[index] + 1\n",
    "\n",
    "    return word_to_index, bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b562b6e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T07:19:34.214947Z",
     "start_time": "2023-01-11T07:19:31.527042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary : {'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n",
      "bag of words vector : [1, 2, 1, 1, 2, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# 문서1\n",
    "doc1 = \"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\"\n",
    "vocab, bow = build_bag_of_words(doc1)\n",
    "print('vocabulary :', vocab)\n",
    "print('bag of words vector :', bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0617e3",
   "metadata": {},
   "source": [
    "> 인덱스 1값인 '가'와 4값인 '물가상승률'은 2번씩 언급되었으므로 BoW의 값이 2이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4833ee43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T07:21:16.265545Z",
     "start_time": "2023-01-11T07:21:16.228446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary : {'소비자': 0, '는': 1, '주로': 2, '소비': 3, '하는': 4, '상품': 5, '을': 6, '기준': 7, '으로': 8, '물가상승률': 9, '느낀다': 10}\n",
      "bag of words vector : [1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# 문서2\n",
    "doc2 = '소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.'\n",
    "\n",
    "vocab, bow = build_bag_of_words(doc2)\n",
    "print('vocabulary :', vocab)\n",
    "print('bag of words vector :', bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "578a28c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T07:21:27.979891Z",
     "start_time": "2023-01-11T07:21:27.933681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary : {'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9, '는': 10, '주로': 11, '소비': 12, '상품': 13, '을': 14, '기준': 15, '으로': 16, '느낀다': 17}\n",
      "bag of words vector : [1, 2, 1, 2, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# 문서3 = 문서1 + 문서2\n",
    "doc3 = doc1 + ' ' + doc2\n",
    "vocab, bow = build_bag_of_words(doc3)\n",
    "print('vocabulary :', vocab)\n",
    "print('bag of words vector :', bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1f66ae",
   "metadata": {},
   "source": [
    "* BoW는 여러 문서의 단어 집합을 합친 뒤에, 해당 단어 집합에 대한 각 문서의 BoW를 구할 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448220ca",
   "metadata": {},
   "source": [
    "> BoW는 주로 **분류 문제나 여러 문서 간의 유사도를 구하는 문제**에 주로 쓰인다.   \n",
    "> 가령,  '미분', '방정식', '부등식'과 같은 단어가 자주 등장한다면 수학 관련 문서로 분류할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5afae4e",
   "metadata": {},
   "source": [
    "## 2.2 CounterVectorizer 클래스로 BoW 만들기\n",
    "- 단어의 빈도를 Count하여 Vector로 만들어준다.\n",
    "- 기본적으로 길이가 2이상인 문자에 대해서만 토큰으로 인식한다. (ex. I는 토큰 X)\n",
    "- 주의) 단지 띄어쓰기만을 기준으로 단어를 자르는 낮은 수준의 토큰화를 진행하고 BoW를 만든다. -> 영어의 경우 문제 없지만, 한국어에 적용시 BoW가 제대로 만들어지지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6014e7b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T07:28:00.335750Z",
     "start_time": "2023-01-11T07:28:00.313866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words vector : [[1 1 2 1 2 1]]\n",
      "vocabulary : {'you': 4, 'know': 1, 'want': 3, 'your': 5, 'love': 2, 'because': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = ['you know I want your love. because I love you.']\n",
    "vector = CountVectorizer()\n",
    "\n",
    "# 코퍼스로부터 각 단어의 빈도수를 기록\n",
    "print('bag of words vector :', vector.fit_transform(corpus).toarray()) \n",
    "\n",
    "# 각 단어의 인덱스가 어떻게 부여되었는지를 출력\n",
    "print('vocabulary :',vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927ad43f",
   "metadata": {},
   "source": [
    "## 2.3 불용어를 제거한 BoW 만들기\n",
    "BoW 사용 이유는 문서 내에서 단어의 등장 빈도수를 보겠다는 것인데, 이것은 결국 텍스트 내에서 어떤 단어들이 중요한지를 보겠다는 의미이다.   \n",
    "따라서 BoW를 만들때 불용어를 제거하면 자연어 처리의 정확도를 높일 수 있을 것이다.\n",
    "\n",
    "영어의 BoW를 만들기 위해 사용하는 CountVectorizer는 불용어를 지정하면, 불용어는 제외하고 BoW를 만들 수 있도록 불용어 제거 기능을 지원하고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91974d26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T07:31:09.647494Z",
     "start_time": "2023-01-11T07:31:08.684889Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bcc703b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T07:31:25.038663Z",
     "start_time": "2023-01-11T07:31:25.018663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words vector : [[1 1 1 1 1]]\n",
      "vocabulary : {'family': 1, 'important': 2, 'thing': 4, 'it': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "# 1) 사용자가 직접 정의한 불용어 사용\n",
    "text = [\"Family is not an important thing. It's everything.\"]\n",
    "vect = CountVectorizer(stop_words=[\"the\", \"a\", \"an\", \"is\", \"not\"])\n",
    "print('bag of words vector :',vect.fit_transform(text).toarray())\n",
    "print('vocabulary :',vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c84df4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T07:31:36.338088Z",
     "start_time": "2023-01-11T07:31:36.316710Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words vector : [[1 1 1]]\n",
      "vocabulary : {'family': 0, 'important': 1, 'thing': 2}\n"
     ]
    }
   ],
   "source": [
    "# 2) CountVectorizer에서 제공하는 자체 불용어 사용\n",
    "text = [\"Family is not an important thing. It's everything.\"]\n",
    "vect = CountVectorizer(stop_words=\"english\")\n",
    "print('bag of words vector :',vect.fit_transform(text).toarray())\n",
    "print('vocabulary :',vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3de835d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T07:32:10.759959Z",
     "start_time": "2023-01-11T07:32:10.729928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words vector : [[1 1 1 1]]\n",
      "vocabulary : {'family': 1, 'important': 2, 'thing': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "# 3) NLTK에서 지원하는 불용어 사용\n",
    "text = [\"Family is not an important thing. It's everything.\"]\n",
    "stop_words = stopwords.words(\"english\")\n",
    "vect = CountVectorizer(stop_words=stop_words)\n",
    "print('bag of words vector :',vect.fit_transform(text).toarray()) \n",
    "print('vocabulary :',vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9868c70d",
   "metadata": {},
   "source": [
    "# 3. 문서 단어 행렬(Document-Term Matrix, DTM)\n",
    "- 다수의 문서에서 등장하는 각 단어들의 빈도를 행렬로 표현한 것   \n",
    "  (각 문서에 대한 BoW를 하나의 행렬로 만든 것)\n",
    "- 행과 열을 반대로 선택하면 TDM이라고 부르기도 한다.\n",
    "- 장점) 문서들을 서로 비교할 수 있도록 수치화할 수 있다.\n",
    "- 필요에 따라서는 형태소 분석기로 단어 토큰화를 수행하고, 불용어에 해당되는 조사들 또한 제거하여 더 정제된 DTM을 만들 수도 있을 것\n",
    "\n",
    "< DTM의 한계 >\n",
    "1) 희소 표현(Sparse representation)   \n",
    "- 공간적 낭비와 계산 리소스를 증가시킨다. (원-핫 벡터와 동일한 단점..)\n",
    "    \n",
    "2) 단순 빈도 수 기반 접근   \n",
    "- ex) 불용어인 the는 어떤 문서이든 자주 등장. but 유사도 비교 시 문서1~3에서 동일하게 the의 빈도수가 높다고 해서 유사한 문서하고 판단해서는 안 된다.   \n",
    "- DTM에 불용어와 중요단어에 대해 가중치는 주는 아이디어를 적용한 게 TF-IDF이다!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd8659e",
   "metadata": {},
   "source": [
    "# 4. TF-IDF(단어 빈도-역문서 빈도, Term Frequency-Inverse Document Frequency)\n",
    "- 단어의 빈도와 역 문서 빈도(문서의 빈도에 특정 식을 취함)를 사용하여 DTM 내의 각 단어들마다 중요한 정도를 가중치로 주는 방법\n",
    "- 우선 DTM을 만든 후, TF-IDF 가중치를 부여\n",
    "- 문서의 유사도를 구하는 작업, 검색 시스템에서 검색 결과의 중요도를 정하는 작업, 문서 내에서 특정 단어의 중요도를 구하는 작업 등에 사용\n",
    "\n",
    "\n",
    "- TF-IDF는 TF와 IDF를 곱한 값을 의미한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5efca872",
   "metadata": {},
   "source": [
    "## 4.1 기본개념\n",
    "문서를 d, 단어를 t, 문서의 총 개수를 n이라 할 때\n",
    "1) **tf(d,t)** : 특정 문서 d에서의 특정 단어 t의 등장 횟수 ( = DTM의 값 )   \n",
    "- 중요도와 비례\n",
    "\n",
    "2) df(t) : 특정 단어 t가 등장한 문서의 수. (각 문서에서 몇 번 등장했는지는 중요하지 X)   \n",
    "- 중요도와 반비례   \n",
    "\n",
    "3) **idf(d, t)** : df(t)에 반비례하는 수.\n",
    "![그림2](./04-2.png) \n",
    "- df에 역수를 취하는 이유 : 중요도와 비례하는 tf값과 곱하기 위해   \n",
    "  (df가 클수록 중요도가 낮다. 즉 idf가 클수록 중요도가 높다.)\n",
    "- log(보통 자연로그 ln 사용)를 쓰는 이유 : 역수를 취한 값이 기하급수적으로 커지는 것을 방지하기 위함\n",
    "- 분모에 1 더하는 이유 : 분모가 0이 되는 상황을 방지하기 위함\n",
    "- **idf값이 클수록 특정 문서에서만 단어 t가 등장한다.**\n",
    "- 여러 문서에서 등장한 단어의 가중치를 낮추는 역할을 해준다.\n",
    "\n",
    "TF-IDF는 모든 문서에서 자주 등장하는 단어는 중요도가 낮다고 판단하며, **_특정 문서에서만 자주 등장하는 단어는 중요도가 높다고 판단한다._**  또한 TF-IDF값은 **중요도와 비례**한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6d4fbf",
   "metadata": {},
   "source": [
    "## 4.2 파이썬으로 TF-IDF 직접 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d04f7d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T08:57:29.721968Z",
     "start_time": "2023-01-11T08:57:28.645978Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd # 데이터프레임 사용을 위해\n",
    "from math import log # IDF 계산을 위해\n",
    "\n",
    "docs = [\n",
    "  '먹고 싶은 사과',\n",
    "  '먹고 싶은 바나나',\n",
    "  '길고 노란 바나나 바나나',\n",
    "  '저는 과일이 좋아요'\n",
    "] \n",
    "vocab = list(set(w for doc in docs for w in doc.split()))\n",
    "vocab.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e6a07b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T08:58:16.998595Z",
     "start_time": "2023-01-11T08:58:16.980038Z"
    }
   },
   "outputs": [],
   "source": [
    "# tf, idf, tf-idf 구하는 함수 구현\n",
    "\n",
    "N = len(docs)  # 총 문서의 수\n",
    "\n",
    "def tf(t, d):\n",
    "    return d.count(t)\n",
    "\n",
    "def idf(t):\n",
    "    df = 0\n",
    "    for doc in docs:\n",
    "        df += t in doc\n",
    "    return log(N/(df+1))\n",
    "\n",
    "def tfidf(t, d):\n",
    "    return tf(t,d)* idf(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a952e8b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T08:59:15.664060Z",
     "start_time": "2023-01-11T08:59:15.629127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과일이</th>\n",
       "      <th>길고</th>\n",
       "      <th>노란</th>\n",
       "      <th>먹고</th>\n",
       "      <th>바나나</th>\n",
       "      <th>사과</th>\n",
       "      <th>싶은</th>\n",
       "      <th>저는</th>\n",
       "      <th>좋아요</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   과일이  길고  노란  먹고  바나나  사과  싶은  저는  좋아요\n",
       "0    0   0   0   1    0   1   1   0    0\n",
       "1    0   0   0   1    1   0   1   0    0\n",
       "2    0   1   1   0    2   0   0   0    0\n",
       "3    1   0   0   0    0   0   0   1    1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DTM을 DF에 저장하여 출력 = TF\n",
    "result = []\n",
    "\n",
    "# 각 문서에 대해서 아래 연산을 반복\n",
    "for i in range(N):\n",
    "    result.append([])\n",
    "    d = docs[i]\n",
    "    for j in range(len(vocab)):\n",
    "        t = vocab[j]\n",
    "        result[-1].append(tf(t, d))\n",
    "\n",
    "tf_ = pd.DataFrame(result, columns = vocab)\n",
    "tf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f185efc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T08:59:41.584577Z",
     "start_time": "2023-01-11T08:59:41.557116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>과일이</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>길고</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>노란</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>먹고</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>바나나</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>사과</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>싶은</th>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>저는</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>좋아요</th>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          IDF\n",
       "과일이  0.693147\n",
       "길고   0.693147\n",
       "노란   0.693147\n",
       "먹고   0.287682\n",
       "바나나  0.287682\n",
       "사과   0.693147\n",
       "싶은   0.287682\n",
       "저는   0.693147\n",
       "좋아요  0.693147"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 단어에 대한 IDF값 구하기\n",
    "result = []\n",
    "for j in range(len(vocab)):\n",
    "    t = vocab[j]\n",
    "    result.append(idf(t))\n",
    "\n",
    "idf_ = pd.DataFrame(result, index=vocab, columns=[\"IDF\"])\n",
    "idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1709bcae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T09:00:09.186243Z",
     "start_time": "2023-01-11T09:00:09.158033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과일이</th>\n",
       "      <th>길고</th>\n",
       "      <th>노란</th>\n",
       "      <th>먹고</th>\n",
       "      <th>바나나</th>\n",
       "      <th>사과</th>\n",
       "      <th>싶은</th>\n",
       "      <th>저는</th>\n",
       "      <th>좋아요</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.287682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.575364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        과일이        길고        노란        먹고       바나나        사과        싶은  \\\n",
       "0  0.000000  0.000000  0.000000  0.287682  0.000000  0.693147  0.287682   \n",
       "1  0.000000  0.000000  0.000000  0.287682  0.287682  0.000000  0.287682   \n",
       "2  0.000000  0.693147  0.693147  0.000000  0.575364  0.000000  0.000000   \n",
       "3  0.693147  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         저는       좋아요  \n",
       "0  0.000000  0.000000  \n",
       "1  0.000000  0.000000  \n",
       "2  0.000000  0.000000  \n",
       "3  0.693147  0.693147  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF 행렬 출력\n",
    "result = []\n",
    "for i in range(N):\n",
    "    result.append([])\n",
    "    d = docs[i]\n",
    "    for j in range(len(vocab)):\n",
    "        t = vocab[j]\n",
    "        result[-1].append(tfidf(t,d))\n",
    "\n",
    "tfidf_ = pd.DataFrame(result, columns = vocab)\n",
    "tfidf_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be49cf",
   "metadata": {},
   "source": [
    "> 위의 기본적인 식을 바탕으로 한 구현에는 몇 가지 문제점이 존재하기 때문에 실제 TF-IDF 구현을 제공하고 있는 많은 머신 러닝 패키지들은 약간씩 조정된 식을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1185cca5",
   "metadata": {},
   "source": [
    "## 4.3 사이킷런을 이용한 DTM과 TF-IDF 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bfe910e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T09:03:10.339538Z",
     "start_time": "2023-01-11T09:03:10.308460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 0 1 0 1 1]\n",
      " [0 0 1 0 0 0 0 1 0]\n",
      " [1 0 0 0 1 0 1 0 0]]\n",
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'you know I want your love',\n",
    "    'I like you',\n",
    "    'what should I do ',    \n",
    "]\n",
    "\n",
    "vector = CountVectorizer()\n",
    "\n",
    "# 코퍼스로부터 각 단어의 빈도수를 기록\n",
    "print(vector.fit_transform(corpus).toarray())   ## DTM 완성! = TF\n",
    "\n",
    "# 각 단어와 맵핑된 인덱스 출력\n",
    "print(vector.vocabulary_)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbdc3410",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-11T09:06:43.428369Z",
     "start_time": "2023-01-11T09:06:43.414093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.46735098 0.         0.46735098 0.         0.46735098\n",
      "  0.         0.35543247 0.46735098]\n",
      " [0.         0.         0.79596054 0.         0.         0.\n",
      "  0.         0.60534851 0.        ]\n",
      " [0.57735027 0.         0.         0.         0.57735027 0.\n",
      "  0.57735027 0.         0.        ]]\n",
      "{'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF를 자동 계산해주는 TfidfVectorizer 이용해보기\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\n",
    "    'you know I want your love',\n",
    "    'I like you',\n",
    "    'what should I do ',    \n",
    "]\n",
    "\n",
    "tfidfv = TfidfVectorizer().fit(corpus)  # 말뭉치 학습\n",
    "print(tfidfv.transform(corpus).toarray())   # TF-IDF 완성!!\n",
    "print(tfidfv.vocabulary_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
